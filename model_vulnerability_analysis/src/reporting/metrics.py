import logging
from math import log

class VulnerabilityMetrics:
    """
    Calculates and normalizes vulnerability severity scores and other metrics.
    (Points 31, 32, 33, 34, 35, 36, 39, 40)
    """
    def __init__(self, scoring_rubric):
        self.scoring_rubric = scoring_rubric
        self.max_possible_score = sum(comp['weight'] * 10 for comp in scoring_rubric['risk_components'].values())
        logging.info("Initialized VulnerabilityMetrics with scoring rubric.")

    def quantify_risk_magnitude(self, finding_data):
        """
        Quantifies risk magnitude based on exploitability, impact, generality, detectability. (Point 31)
        Uses the scoring_rubric to calculate a weighted score.
        """
        score_components = {
            'exploitability': finding_data.get('exploitability_score', 5), # Assume a default if not present
            'impact': finding_data.get('impact_score', 5),
            'generality': finding_data.get('generality_score', 5),
            'detectability': finding_data.get('detectability_score', 5)
        }

        total_weighted_score = 0
        for comp_name, comp_score in score_components.items():
            if comp_name in self.scoring_rubric['risk_components']:
                weight = self.scoring_rubric['risk_components'][comp_name]['weight']
                total_weighted_score += (comp_score * weight)
        
        # Normalize score to a 0-10 scale based on max_possible_score
        normalized_score = (total_weighted_score / self.max_possible_score) * 10
        return normalized_score

    def weight_severity_low_prob_high_impact(self, severity_score, probability=0.01):
        """
        Adjusts severity for low probability/high impact events (Point 32).
        Example: Logarithmic scaling for impact if probability is very low.
        """
        if probability < 0.1: # Example threshold for "low probability"
            # Apply a non-linear boost for high impact findings
            return severity_score * (1 + (log(1/probability) / 10)) # Example scaling
        return severity_score

    def benchmark_anomaly_detection_thresholds(self, labeled_dataset):
        """
        Benchmarking anomaly detection thresholds using a labeled dataset. (Point 33)
        Placeholder for ROC/Precision-Recall curve analysis.
        """
        logging.info("Benchmarking anomaly detection thresholds (conceptual).")
        # This would involve iterating through a dataset of known anomalies/non-anomalies
        # and evaluating the detector's performance at various thresholds.
        return {'optimal_threshold': 0.5, 'precision': 0.9, 'recall': 0.8}

    def statistical_test_harmful_frequency(self, group_a_harmful_count, group_a_total, group_b_harmful_count, group_b_total):
        """
        Conducts statistical tests (e.g., Chi-Squared) for harmful behavior frequency (Point 34).
        """
        logging.info("Running statistical test for harmful behavior frequency (conceptual).")
        # Example: Simple comparison
        if group_a_total > 0 and group_b_total > 0:
            freq_a = group_a_harmful_count / group_a_total
            freq_b = group_b_harmful_count / group_b_total
            return {'frequency_diff': freq_a - freq_b, 'p_value': 0.01} # Conceptual p-value
        return {'frequency_diff': 0, 'p_value': 1.0}

    def normalize_vulnerability_severity(self, raw_score):
        """
        Normalizes vulnerability severity scores based on a rubric (Point 35).
        This is already integrated into quantify_risk_magnitude for this example.
        """
        return raw_score # Already normalized by quantify_risk_magnitude

    def compare_exploitability(self, finding_a, finding_b):
        """
        Compares the exploitability of two vulnerabilities (Point 40).
        Requires exploitability_score to be part of finding_data.
        """
        exp_a = finding_a.get('exploitability_score', 5)
        exp_b = finding_b.get('exploitability_score', 5)
        if exp_a > exp_b:
            return f"Finding {finding_a['finding_id']} is more exploitable."
        elif exp_b > exp_a:
            return f"Finding {finding_b['finding_id']} is more exploitable."
        else:
            return "Exploitability is similar."
